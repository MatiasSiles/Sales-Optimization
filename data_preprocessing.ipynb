{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlBz9j+GR9aybHc3qQh2tc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatiasSiles/Sales-Optimization/blob/main/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will apply feature engineering, data cleaning, feature selection, etc. For all prepare train the models"
      ],
      "metadata": {
        "id": "ZBQWU-bNJV1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "df = pd.read_csv('/content/Sales_Business.csv')"
      ],
      "metadata": {
        "id": "eQz7ZZ-eKIFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data cleaning for ML models"
      ],
      "metadata": {
        "id": "Auatc835KAev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "i not consider \"return_reason\" for data cleaning because it has 11156 nan, that's a lot but for other side, is a important feature for customer classification. Then, in other situations more information about this column could be requested"
      ],
      "metadata": {
        "id": "0CXIzIG9MfNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important_features_impute_mean = ['customer_age', 'satisfaction_score']\n",
        "\n",
        "for col in important_features_impute_mean:\n",
        "    df[col].fillna(df[col].mean(), inplace=True)\n",
        "\n",
        "df['customer_gender'] = df['customer_gender'].fillna(\"unknown\")\n",
        "\n",
        "df.drop('return_reason', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "L9Jrw0q8KAPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering"
      ],
      "metadata": {
        "id": "Eq3ZTJ61SzsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy for feature engineering\n",
        "df_fe = df.copy()"
      ],
      "metadata": {
        "id": "CE7onbpfS525"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Date-based features\n",
        "df_fe['date'] = pd.to_datetime(df_fe['date'])\n",
        "df_fe['days_since_start'] = (df_fe['date'] - df_fe['date'].min()).dt.days\n",
        "df_fe['week_of_year'] = df_fe['date'].dt.isocalendar().week # the week number of the date, e.g: 2021-08-30 is the week 35 in 2021\n",
        "df_fe['is_month_start'] = df_fe['date'].dt.is_month_start.astype(int) # 1 = if the date is the first day of the month\n",
        "df_fe['is_month_end'] = df_fe['date'].dt.is_month_end.astype(int)\n",
        "df_fe['is_quarter_start'] = df_fe['date'].dt.is_quarter_start.astype(int)\n",
        "df_fe['is_quarter_end'] = df_fe['date'].dt.is_quarter_end.astype(int)\n",
        "df_fe"
      ],
      "metadata": {
        "id": "AIPC6dZ6S24T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Customer-based features\n",
        "customer_stats = df_fe.groupby('customer_id').agg({\n",
        "    'order_id': 'count',\n",
        "    'total_amount': ['sum', 'mean'],\n",
        "    'profit': 'sum',\n",
        "    'date': ['min', 'max']\n",
        "})\n",
        "customer_stats.columns = ['order_frequency', 'total_spent', 'avg_order_value',\n",
        "                          'total_profit_generated', 'first_purchase', 'last_purchase']\n",
        "\n",
        "# Calculate recency (days since last purchase)\n",
        "customer_stats['recency_days'] = (df_fe['date'].max() - customer_stats['last_purchase']).dt.days\n",
        "customer_stats['customer_lifetime_days'] = (customer_stats['last_purchase'] - customer_stats['first_purchase']).dt.days"
      ],
      "metadata": {
        "id": "7Uyjlfy2TCKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_fe = df_fe.merge(customer_stats, left_on='customer_id', right_index=True, how='left')\n",
        "df_fe = df_fe.merge(customer_stats, on='customer_id', how='left')"
      ],
      "metadata": {
        "id": "Y5jL0fEyXflt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Product-based features\n",
        "# Product performance metrics\n",
        "product_stats = df_fe.groupby('product_name').agg({\n",
        "    'quantity': 'sum',\n",
        "    'total_amount': 'sum',\n",
        "    'profit_margin': 'mean',\n",
        "    'is_returned': 'mean'\n",
        "})\n",
        "product_stats.columns = ['product_total_qty_sold', 'product_total_revenue',\n",
        "                        'product_avg_margin', 'product_return_rate']"
      ],
      "metadata": {
        "id": "yqBbHJEvTM8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fe = df_fe.merge(product_stats, on='product_name', how='left')"
      ],
      "metadata": {
        "id": "tODHwfIAaH8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Sales representative performance\n",
        "rep_stats = df_fe.groupby('sales_rep').agg({\n",
        "    'total_amount': ['sum', 'mean'],\n",
        "    'profit': 'sum',\n",
        "    'satisfaction_score': 'mean'\n",
        "})\n",
        "rep_stats.columns = ['rep_total_sales', 'rep_avg_order_value',\n",
        "                    'rep_total_profit', 'rep_avg_satisfaction']"
      ],
      "metadata": {
        "id": "-1ymHt2vaDuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fe = df_fe.merge(rep_stats, on='sales_rep', how='left')"
      ],
      "metadata": {
        "id": "tpCDibGtaF_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Discount and pricing features\n",
        "df_fe['discount_impact'] = df_fe['discount_amount'] / df_fe['subtotal'] # what proportion of the sale was discounted\n",
        "df_fe['effective_price'] = df_fe['unit_price'] * (1 - df_fe['discount_rate']) # how much each unit is actually sold for, subtracting the discount\n",
        "df_fe['price_per_profit_ratio'] = df_fe['unit_price'] / (df_fe['profit'] + 0.01)  # Avoid division by zero\n",
        "df_fe['is_high_discount'] = (df_fe['discount_rate'] > df_fe['discount_rate'].quantile(0.75)).astype(int)\n",
        "df_fe['discount_category'] = pd.cut(df_fe['discount_rate'],\n",
        "                                    bins=[0, 0.05, 0.15, 0.25, 1.0],\n",
        "                                    labels=['No_Discount', 'Low_Discount', 'Medium_Discount', 'High_Discount'])"
      ],
      "metadata": {
        "id": "HV6O4X2eat91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Order complexity features\n",
        "df_fe['order_complexity'] = df_fe['quantity'] * df_fe.groupby('order_id')['product_name'].transform('nunique') # how many quantities of products does each order have\n",
        "df_fe['is_bulk_order'] = (df_fe['quantity'] > df_fe['quantity'].quantile(0.8)).astype(int)\n",
        "df_fe['shipping_to_total_ratio'] = df_fe['shipping_cost'] / df_fe['total_amount']"
      ],
      "metadata": {
        "id": "y7et3tQNaxUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Seasonal and cyclical features (American calendar)\n",
        "df_fe['is_holiday_season'] = ((df_fe['month'] == 12) | (df_fe['month'] == 1)).astype(int)\n",
        "df_fe['is_summer_season'] = ((df_fe['month'] >= 6) & (df_fe['month'] <= 8)).astype(int)\n",
        "df_fe['is_back_to_school'] = ((df_fe['month'] == 8) | (df_fe['month'] == 9)).astype(int)"
      ],
      "metadata": {
        "id": "PXkyHA3iazgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Risk and quality indicators\n",
        "df_fe['customer_risk_score'] = (\n",
        "    (df_fe['recency_days'] > df_fe['recency_days'].quantile(0.75)) * 0.3 + # to be an updated client\n",
        "    (df_fe['satisfaction_score'] < df_fe['satisfaction_score'].quantile(0.25)) * 0.4 + # low customer satisfaction\n",
        "    (df_fe['is_returned'] == 1) * 0.3 # if the customer returned the order\n",
        ")"
      ],
      "metadata": {
        "id": "TderLLiUa1cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Encoding categorical variables\n",
        "# One-hot encoding for low cardinality categorical variables\n",
        "categorical_to_encode = ['customer_gender', 'customer_segment', 'sales_channel',\n",
        "                        'payment_method', 'day_of_week', 'discount_category']\n",
        "\n",
        "for col in categorical_to_encode:\n",
        "    if col in df_fe.columns:\n",
        "        dummies = pd.get_dummies(df_fe[col], prefix=col, drop_first=True)\n",
        "        df_fe = pd.concat([df_fe, dummies], axis=1)"
      ],
      "metadata": {
        "id": "GEOr65SGa3wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Columns with high cardinality (many unique values) are selected, where one-hot encoding is of little use to the model. What is done is replace each value in each column with the target average. Each categorical value in each column will be the corresponding target average. The variable high_cardinality_cols has columns with many unique values ​​that are repetitive and can affect the performance of the model."
      ],
      "metadata": {
        "id": "wETShrZ0fsP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Target encoding for high cardinality categorical variables\n",
        "high_cardinality_cols = ['product_category', 'product_name', 'region', 'sales_rep', 'lead_source']\n",
        "target_col = 'total_amount'  # Can be changed based on prediction target\n",
        "\n",
        "for col in high_cardinality_cols:\n",
        "    if col in df_fe.columns:\n",
        "        target_mean = df_fe.groupby(col)[target_col].mean()\n",
        "        df_fe[f'{col}_target_encoded'] = df_fe[col].map(target_mean)"
      ],
      "metadata": {
        "id": "1KjTVSVKfq44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, I combine variables that are possibly useful for the models, the interactions of characteristics allow me to know how 2 variables interact in the impact and if they grow together."
      ],
      "metadata": {
        "id": "csiycckgisLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Interaction features\n",
        "df_fe['age_segment_interaction'] = df_fe['customer_age'] * df_fe['customer_segment_Premium']\n",
        "df_fe['price_quantity_interaction'] = df_fe['unit_price'] * df_fe['quantity']\n",
        "df_fe['discount_satisfaction_interaction'] = df_fe['discount_rate'] * df_fe['satisfaction_score']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6ISLjXdRkv4",
        "outputId": "44166c47-c5ea-49f7-eaaf-81889e297219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original features: 31\n",
            "Features after engineering: 97\n",
            "New features created: 66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Info about the new dataset\n",
        "print(f\"Original features: {df.shape[1]}\")\n",
        "print(f\"Total Features after engineering: {df_fe.shape[1]}\")\n",
        "print(f\"New features created: {df_fe.shape[1] - df.shape[1]}\")"
      ],
      "metadata": {
        "id": "pJmxnd5Ei0tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGgAVtdFDEbg"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 8. FEATURE SELECTION AND PREPARATION\n",
        "# ========================================\n",
        "\n",
        "def prepare_features_for_modeling(df_fe):\n",
        "    \"\"\"Prepare features for machine learning models\"\"\"\n",
        "\n",
        "    print(\"=== FEATURE PREPARATION FOR MODELING ===\")\n",
        "\n",
        "    # Remove features not suitable for modeling\n",
        "    columns_to_drop = ['order_id', 'customer_id', 'product_name', 'date',\n",
        "                      'first_purchase', 'last_purchase', 'sales_rep']\n",
        "\n",
        "    # Create modeling dataset\n",
        "    df_model = df_fe.drop(columns=[col for col in columns_to_drop if col in df_fe.columns])\n",
        "\n",
        "    # Handle remaining missing values\n",
        "    # Numerical columns: fill with median\n",
        "    numerical_cols = df_model.select_dtypes(include=[np.number]).columns\n",
        "    df_model[numerical_cols] = df_model[numerical_cols].fillna(df_model[numerical_cols].median())\n",
        "\n",
        "    # Categorical columns: fill with mode\n",
        "    categorical_cols = df_model.select_dtypes(include=['object']).columns\n",
        "    for col in categorical_cols:\n",
        "        df_model[col] = df_model[col].fillna(df_model[col].mode()[0])\n",
        "\n",
        "    # Feature importance analysis using correlation with target variables\n",
        "    target_variables = ['total_amount', 'profit', 'satisfaction_score', 'is_returned']\n",
        "\n",
        "    print(\"TOP 20 FEATURES BY CORRELATION WITH TARGETS:\")\n",
        "    for target in target_variables:\n",
        "        if target in df_model.columns:\n",
        "            correlations = df_model.corr()[target].abs().sort_values(ascending=False)\n",
        "            print(f\"\\nTop features correlated with {target}:\")\n",
        "            print(correlations.head(10))\n",
        "\n",
        "    print(f\"\\nFinal dataset shape for modeling: {df_model.shape}\")\n",
        "    print(f\"Features ready for ML: {df_model.shape[1]}\")\n",
        "\n",
        "    return df_model"
      ]
    }
  ]
}