{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOI4Y6InjwO/iBteq3SpmGr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatiasSiles/Sales-Optimization/blob/main/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will apply feature engineering, data cleaning, feature selection, etc. For all prepare train the models"
      ],
      "metadata": {
        "id": "ZBQWU-bNJV1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "df = pd.read_csv('/content/Sales_Business.csv')"
      ],
      "metadata": {
        "id": "eQz7ZZ-eKIFL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data cleaning for ML models"
      ],
      "metadata": {
        "id": "Auatc835KAev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "i not consider \"return_reason\" for data cleaning because it has 11156 nan, that's a lot but for other side, is a important feature for customer classification. Then, in other situations more information about this column could be requested"
      ],
      "metadata": {
        "id": "0CXIzIG9MfNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "important_features_impute_mean = ['customer_age', 'satisfaction_score']\n",
        "\n",
        "for col in important_features_impute_mean:\n",
        "    df[col].fillna(df[col].mean(), inplace=True)\n",
        "\n",
        "df['customer_gender'] = df['customer_gender'].fillna(\"unknown\")\n",
        "\n",
        "df.drop('return_reason', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "L9Jrw0q8KAPO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering"
      ],
      "metadata": {
        "id": "Eq3ZTJ61SzsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy for feature engineering\n",
        "df_fe = df.copy()"
      ],
      "metadata": {
        "id": "CE7onbpfS525"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Date-based features\n",
        "df_fe['date'] = pd.to_datetime(df_fe['date'])\n",
        "df_fe['days_since_start'] = (df_fe['date'] - df_fe['date'].min()).dt.days\n",
        "df_fe['week_of_year'] = df_fe['date'].dt.isocalendar().week # the week number of the date, e.g: 2021-08-30 is the week 35 in 2021\n",
        "df_fe['is_month_start'] = df_fe['date'].dt.is_month_start.astype(int) # 1 = if the date is the first day of the month\n",
        "df_fe['is_month_end'] = df_fe['date'].dt.is_month_end.astype(int)\n",
        "df_fe['is_quarter_start'] = df_fe['date'].dt.is_quarter_start.astype(int)\n",
        "df_fe['is_quarter_end'] = df_fe['date'].dt.is_quarter_end.astype(int)\n",
        "df_fe"
      ],
      "metadata": {
        "id": "AIPC6dZ6S24T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Customer-based features\n",
        "customer_stats = df_fe.groupby('customer_id').agg({\n",
        "    'order_id': 'count',\n",
        "    'total_amount': ['sum', 'mean'],\n",
        "    'profit': 'sum',\n",
        "    'date': ['min', 'max']\n",
        "})\n",
        "customer_stats.columns = ['order_frequency', 'total_spent', 'avg_order_value',\n",
        "                          'total_profit_generated', 'first_purchase', 'last_purchase']\n",
        "\n",
        "# Calculate recency (days since last purchase)\n",
        "customer_stats['recency_days'] = (df_fe['date'].max() - customer_stats['last_purchase']).dt.days\n",
        "customer_stats['customer_lifetime_days'] = (customer_stats['last_purchase'] - customer_stats['first_purchase']).dt.days"
      ],
      "metadata": {
        "id": "7Uyjlfy2TCKw"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_fe = df_fe.merge(customer_stats, left_on='customer_id', right_index=True, how='left')\n",
        "df_fe = df_fe.merge(customer_stats, on='customer_id', how='left')"
      ],
      "metadata": {
        "id": "Y5jL0fEyXflt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Product-based features\n",
        "# Product performance metrics\n",
        "product_stats = df_fe.groupby('product_name').agg({\n",
        "    'quantity': 'sum',\n",
        "    'total_amount': 'sum',\n",
        "    'profit_margin': 'mean',\n",
        "    'is_returned': 'mean'\n",
        "})\n",
        "product_stats.columns = ['product_total_qty_sold', 'product_total_revenue',\n",
        "                        'product_avg_margin', 'product_return_rate']"
      ],
      "metadata": {
        "id": "yqBbHJEvTM8Y"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fe = df_fe.merge(product_stats, on='product_name', how='left')"
      ],
      "metadata": {
        "id": "tODHwfIAaH8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Sales representative performance\n",
        "rep_stats = df_fe.groupby('sales_rep').agg({\n",
        "    'total_amount': ['sum', 'mean'],\n",
        "    'profit': 'sum',\n",
        "    'satisfaction_score': 'mean'\n",
        "})\n",
        "rep_stats.columns = ['rep_total_sales', 'rep_avg_order_value',\n",
        "                    'rep_total_profit', 'rep_avg_satisfaction']"
      ],
      "metadata": {
        "id": "-1ymHt2vaDuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fe = df_fe.merge(rep_stats, on='sales_rep', how='left')"
      ],
      "metadata": {
        "id": "tpCDibGtaF_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Discount and pricing features\n",
        "df_fe['discount_impact'] = df_fe['discount_amount'] / df_fe['subtotal']\n",
        "df_fe['effective_price'] = df_fe['unit_price'] * (1 - df_fe['discount_rate'])\n",
        "df_fe['price_per_profit_ratio'] = df_fe['unit_price'] / (df_fe['profit'] + 0.01)  # Avoid division by zero\n",
        "df_fe['is_high_discount'] = (df_fe['discount_rate'] > df_fe['discount_rate'].quantile(0.75)).astype(int)\n",
        "df_fe['discount_category'] = pd.cut(df_fe['discount_rate'],\n",
        "                                    bins=[0, 0.05, 0.15, 0.25, 1.0],\n",
        "                                    labels=['No_Discount', 'Low_Discount', 'Medium_Discount', 'High_Discount'])"
      ],
      "metadata": {
        "id": "HV6O4X2eat91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Order complexity features\n",
        "df_fe['order_complexity'] = df_fe['quantity'] * df_fe.groupby('order_id')['product_name'].transform('nunique')\n",
        "df_fe['is_bulk_order'] = (df_fe['quantity'] > df_fe['quantity'].quantile(0.8)).astype(int)\n",
        "df_fe['shipping_to_total_ratio'] = df_fe['shipping_cost'] / df_fe['total_amount']"
      ],
      "metadata": {
        "id": "y7et3tQNaxUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Seasonal and cyclical features\n",
        "df_fe['is_holiday_season'] = ((df_fe['month'] == 12) | (df_fe['month'] == 1)).astype(int)\n",
        "df_fe['is_summer_season'] = ((df_fe['month'] >= 6) & (df_fe['month'] <= 8)).astype(int)\n",
        "df_fe['is_back_to_school'] = ((df_fe['month'] == 8) | (df_fe['month'] == 9)).astype(int)"
      ],
      "metadata": {
        "id": "PXkyHA3iazgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Risk and quality indicators\n",
        "df_fe['customer_risk_score'] = (\n",
        "    (df_fe['recency_days'] > df_fe['recency_days'].quantile(0.75)) * 0.3 +\n",
        "    (df_fe['satisfaction_score'] < df_fe['satisfaction_score'].quantile(0.25)) * 0.4 +\n",
        "    (df_fe['is_returned'] == 1) * 0.3\n",
        ")"
      ],
      "metadata": {
        "id": "TderLLiUa1cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Encoding categorical variables\n",
        "# One-hot encoding for low cardinality categorical variables\n",
        "categorical_to_encode = ['customer_gender', 'customer_segment', 'sales_channel',\n",
        "                        'payment_method', 'day_of_week', 'discount_category']\n",
        "\n",
        "for col in categorical_to_encode:\n",
        "    if col in df_fe.columns:\n",
        "        dummies = pd.get_dummies(df_fe[col], prefix=col, drop_first=True)\n",
        "        df_fe = pd.concat([df_fe, dummies], axis=1)\n",
        "\n",
        "# Target encoding for high cardinality categorical variables\n",
        "high_cardinality_cols = ['product_category', 'product_name', 'region', 'sales_rep', 'lead_source']\n",
        "target_col = 'total_amount'  # Can be changed based on prediction target\n",
        "\n",
        "for col in high_cardinality_cols:\n",
        "    if col in df_fe.columns:\n",
        "        target_mean = df_fe.groupby(col)[target_col].mean()\n",
        "        df_fe[f'{col}_target_encoded'] = df_fe[col].map(target_mean)"
      ],
      "metadata": {
        "id": "GEOr65SGa3wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Interaction features\n",
        "df_fe['age_segment_interaction'] = df_fe['customer_age'] * df_fe['customer_segment_Premium']\n",
        "df_fe['price_quantity_interaction'] = df_fe['unit_price'] * df_fe['quantity']\n",
        "df_fe['discount_satisfaction_interaction'] = df_fe['discount_rate'] * df_fe['satisfaction_score']\n",
        "\n",
        "print(f\"Original features: {df.shape[1]}\")\n",
        "print(f\"Features after engineering: {df_fe.shape[1]}\")\n",
        "print(f\"New features created: {df_fe.shape[1] - df.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6ISLjXdRkv4",
        "outputId": "44166c47-c5ea-49f7-eaaf-81889e297219"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original features: 31\n",
            "Features after engineering: 97\n",
            "New features created: 66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ZGgAVtdFDEbg"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 7. FEATURE ENGINEERING\n",
        "# ========================================\n",
        "\n",
        "def feature_engineering(df):\n",
        "    \"\"\"Comprehensive feature engineering for predictive modeling\"\"\"\n",
        "\n",
        "    print(\"=== FEATURE ENGINEERING ===\")\n",
        "\n",
        "    # Create a copy for feature engineering\n",
        "    df_fe = df.copy()\n",
        "\n",
        "    # 1. Date-based features\n",
        "    df_fe['date'] = pd.to_datetime(df_fe['date'])\n",
        "    df_fe['days_since_start'] = (df_fe['date'] - df_fe['date'].min()).dt.days\n",
        "    df_fe['week_of_year'] = df_fe['date'].dt.isocalendar().week\n",
        "    df_fe['is_month_start'] = df_fe['date'].dt.is_month_start.astype(int)\n",
        "    df_fe['is_month_end'] = df_fe['date'].dt.is_month_end.astype(int)\n",
        "    df_fe['is_quarter_start'] = df_fe['date'].dt.is_quarter_start.astype(int)\n",
        "    df_fe['is_quarter_end'] = df_fe['date'].dt.is_quarter_end.astype(int)\n",
        "\n",
        "    # 2. Customer-based features\n",
        "    # Customer frequency and recency\n",
        "    customer_stats = df_fe.groupby('customer_id').agg({\n",
        "        'order_id': 'count',\n",
        "        'total_amount': ['sum', 'mean'],\n",
        "        'profit': 'sum',\n",
        "        'date': ['min', 'max']\n",
        "    })\n",
        "    customer_stats.columns = ['order_frequency', 'total_spent', 'avg_order_value',\n",
        "                             'total_profit_generated', 'first_purchase', 'last_purchase']\n",
        "\n",
        "    # Calculate recency (days since last purchase)\n",
        "    customer_stats['recency_days'] = (df_fe['date'].max() - customer_stats['last_purchase']).dt.days\n",
        "    customer_stats['customer_lifetime_days'] = (customer_stats['last_purchase'] - customer_stats['first_purchase']).dt.days\n",
        "\n",
        "    # Merge back to main dataset\n",
        "    df_fe = df_fe.merge(customer_stats, left_on='customer_id', right_index=True, how='left')\n",
        "\n",
        "    # 3. Product-based features\n",
        "    # Product performance metrics\n",
        "    product_stats = df_fe.groupby('product_name').agg({\n",
        "        'quantity': 'sum',\n",
        "        'total_amount': 'sum',\n",
        "        'profit_margin': 'mean',\n",
        "        'is_returned': 'mean'\n",
        "    })\n",
        "    product_stats.columns = ['product_total_qty_sold', 'product_total_revenue',\n",
        "                            'product_avg_margin', 'product_return_rate']\n",
        "\n",
        "    df_fe = df_fe.merge(product_stats, left_on='product_name', right_index=True, how='left')\n",
        "\n",
        "    # 4. Sales representative performance\n",
        "    rep_stats = df_fe.groupby('sales_rep').agg({\n",
        "        'total_amount': ['sum', 'mean'],\n",
        "        'profit': 'sum',\n",
        "        'satisfaction_score': 'mean'\n",
        "    })\n",
        "    rep_stats.columns = ['rep_total_sales', 'rep_avg_order_value',\n",
        "                        'rep_total_profit', 'rep_avg_satisfaction']\n",
        "\n",
        "    df_fe = df_fe.merge(rep_stats, left_on='sales_rep', right_index=True, how='left')\n",
        "\n",
        "    # 5. Discount and pricing features\n",
        "    df_fe['discount_impact'] = df_fe['discount_amount'] / df_fe['subtotal']\n",
        "    df_fe['effective_price'] = df_fe['unit_price'] * (1 - df_fe['discount_rate'])\n",
        "    df_fe['price_per_profit_ratio'] = df_fe['unit_price'] / (df_fe['profit'] + 0.01)  # Avoid division by zero\n",
        "    df_fe['is_high_discount'] = (df_fe['discount_rate'] > df_fe['discount_rate'].quantile(0.75)).astype(int)\n",
        "    df_fe['discount_category'] = pd.cut(df_fe['discount_rate'],\n",
        "                                       bins=[0, 0.05, 0.15, 0.25, 1.0],\n",
        "                                       labels=['No_Discount', 'Low_Discount', 'Medium_Discount', 'High_Discount'])\n",
        "\n",
        "    # 6. Order complexity features\n",
        "    df_fe['order_complexity'] = df_fe['quantity'] * df_fe.groupby('order_id')['product_name'].transform('nunique')\n",
        "    df_fe['is_bulk_order'] = (df_fe['quantity'] > df_fe['quantity'].quantile(0.8)).astype(int)\n",
        "    df_fe['shipping_to_total_ratio'] = df_fe['shipping_cost'] / df_fe['total_amount']\n",
        "\n",
        "    # 7. Seasonal and cyclical features\n",
        "    df_fe['is_holiday_season'] = ((df_fe['month'] == 12) | (df_fe['month'] == 1)).astype(int)\n",
        "    df_fe['is_summer_season'] = ((df_fe['month'] >= 6) & (df_fe['month'] <= 8)).astype(int)\n",
        "    df_fe['is_back_to_school'] = ((df_fe['month'] == 8) | (df_fe['month'] == 9)).astype(int)\n",
        "\n",
        "    # 8. Risk and quality indicators\n",
        "    df_fe['customer_risk_score'] = (\n",
        "        (df_fe['recency_days'] > df_fe['recency_days'].quantile(0.75)) * 0.3 +\n",
        "        (df_fe['satisfaction_score'] < df_fe['satisfaction_score'].quantile(0.25)) * 0.4 +\n",
        "        (df_fe['is_returned'] == 1) * 0.3\n",
        "    )\n",
        "\n",
        "    # 9. Encoding categorical variables\n",
        "    # One-hot encoding for low cardinality categorical variables\n",
        "    categorical_to_encode = ['customer_gender', 'customer_segment', 'sales_channel',\n",
        "                           'payment_method', 'day_of_week', 'discount_category']\n",
        "\n",
        "    for col in categorical_to_encode:\n",
        "        if col in df_fe.columns:\n",
        "            dummies = pd.get_dummies(df_fe[col], prefix=col, drop_first=True)\n",
        "            df_fe = pd.concat([df_fe, dummies], axis=1)\n",
        "\n",
        "    # Target encoding for high cardinality categorical variables\n",
        "    high_cardinality_cols = ['product_category', 'product_name', 'region', 'sales_rep', 'lead_source']\n",
        "    target_col = 'total_amount'  # Can be changed based on prediction target\n",
        "\n",
        "    for col in high_cardinality_cols:\n",
        "        if col in df_fe.columns:\n",
        "            target_mean = df_fe.groupby(col)[target_col].mean()\n",
        "            df_fe[f'{col}_target_encoded'] = df_fe[col].map(target_mean)\n",
        "\n",
        "    # 10. Interaction features\n",
        "    df_fe['age_segment_interaction'] = df_fe['customer_age'] * df_fe['customer_segment_Premium']\n",
        "    df_fe['price_quantity_interaction'] = df_fe['unit_price'] * df_fe['quantity']\n",
        "    df_fe['discount_satisfaction_interaction'] = df_fe['discount_rate'] * df_fe['satisfaction_score']\n",
        "\n",
        "    print(f\"Original features: {df.shape[1]}\")\n",
        "    print(f\"Features after engineering: {df_fe.shape[1]}\")\n",
        "    print(f\"New features created: {df_fe.shape[1] - df.shape[1]}\")\n",
        "\n",
        "    return df_fe\n",
        "\n",
        "# ========================================\n",
        "# 8. FEATURE SELECTION AND PREPARATION\n",
        "# ========================================\n",
        "\n",
        "def prepare_features_for_modeling(df_fe):\n",
        "    \"\"\"Prepare features for machine learning models\"\"\"\n",
        "\n",
        "    print(\"=== FEATURE PREPARATION FOR MODELING ===\")\n",
        "\n",
        "    # Remove features not suitable for modeling\n",
        "    columns_to_drop = ['order_id', 'customer_id', 'product_name', 'date',\n",
        "                      'first_purchase', 'last_purchase', 'sales_rep']\n",
        "\n",
        "    # Create modeling dataset\n",
        "    df_model = df_fe.drop(columns=[col for col in columns_to_drop if col in df_fe.columns])\n",
        "\n",
        "    # Handle remaining missing values\n",
        "    # Numerical columns: fill with median\n",
        "    numerical_cols = df_model.select_dtypes(include=[np.number]).columns\n",
        "    df_model[numerical_cols] = df_model[numerical_cols].fillna(df_model[numerical_cols].median())\n",
        "\n",
        "    # Categorical columns: fill with mode\n",
        "    categorical_cols = df_model.select_dtypes(include=['object']).columns\n",
        "    for col in categorical_cols:\n",
        "        df_model[col] = df_model[col].fillna(df_model[col].mode()[0])\n",
        "\n",
        "    # Feature importance analysis using correlation with target variables\n",
        "    target_variables = ['total_amount', 'profit', 'satisfaction_score', 'is_returned']\n",
        "\n",
        "    print(\"TOP 20 FEATURES BY CORRELATION WITH TARGETS:\")\n",
        "    for target in target_variables:\n",
        "        if target in df_model.columns:\n",
        "            correlations = df_model.corr()[target].abs().sort_values(ascending=False)\n",
        "            print(f\"\\nTop features correlated with {target}:\")\n",
        "            print(correlations.head(10))\n",
        "\n",
        "    print(f\"\\nFinal dataset shape for modeling: {df_model.shape}\")\n",
        "    print(f\"Features ready for ML: {df_model.shape[1]}\")\n",
        "\n",
        "    return df_model"
      ]
    }
  ]
}